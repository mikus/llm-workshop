{
    "cells": [
        {
            "language": "markdown",
            "source": [
                "# LLM Workshop\n## Lab 5: Langchain Agents\n\nIn this notebook, we use an LLM's reasoning capabilities to plan and execute actions in order to solve a task.\n\nWe will be using [LangChain tools](https://js.langchain.com/docs/concepts/tools/) to allow LLMs to interface with external sources. Tools are functions or APIs which helps provides the LLM with the relevant context. We will be examining some popular built-in tool integrations in this notebook.\n\n[Agents](https://python.langchain.com/docs/concepts/agents/) harness the reasoning capabilities of LLMs to plan actions to solve the task. LangChain agents have the capability to not only plan but also execute the actions decided upon. An agent can be given access to tools which the agent may select to solve the task. In chains, a sequence of actions is hardcoded. In agents, an LLM uses its reasoning to choose which actions to take and in which order.\n\nIn this notebook we will develop custom agents with access to certain tools, and observe how the agent selects the appropriate tool, retrieves the results using the selected tool and produces the final response.\n\n---\n    \nPlease work top to bottom of this notebook and don't skip sections as this could lead to error messages due to missing code."
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Setup\nLet's install necessary libraries"
            ],
            "outputs": []
        },
        {
            "language": "shellscript",
            "source": [
                "npm install"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "",
                                "up to date, audited 186 packages in 750ms",
                                "",
                                "44 packages are looking for funding",
                                "  run `npm fund` for details",
                                "",
                                "found 0 vulnerabilities",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "And import what is needed"
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "// read local environment variables from .env\nrequire('dotenv').config();\n\n// This module is built into the notebook. You do not need to install this.\nconst { display } = require('node-kernel');\n\nimport { ChatOpenAI } from \"@langchain/openai\";\nconst chat = new ChatOpenAI({\n    apiKey: process.env.OPENAI_API_KEY,\n    modelName: \"gpt-4o-mini\",\n});\n\nimport { PromptTemplate, ChatPromptTemplate } from \"@langchain/core/prompts\";"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "## Tools and Toolkits\n\nTools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models. Tools are needed whenever you want a model to control parts of your code or call out to external APIs.\n\nA tool consists of:\n\n* The name of the tool.\n* A description of what the tool does.\n* A JSON schema defining the inputs to the tool.\n* A function (and, optionally, an async variant of the function).\n\nWhen a tool is bound to a model, the name, description and JSON schema are provided as context to the model. Given a list of tools and a set of instructions, a model can request to call one or more tools with specific inputs.\n\nToolkits are collections of tools that are designed to be used together for specific tasks. They have convenient loading methods."
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "### Wikipedia Tool\n\n[Wikipedia](https://wikipedia.org/) is a multilingual free online encyclopedia written and maintained by a community of volunteers, through open collaboration. Wikipedia is the largest and most-read reference work in history.\n\nTo use the wikipedia tool, you need to first install `wikipedia` package."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { WikipediaQueryRun } from \"@langchain/community/tools/wikipedia_query_run\";\n\nconst wikipediaTool = new WikipediaQueryRun({\n    topKResults: 3,\n    maxDocContentLength: 4000,\n});\n\nconst response = await wikipediaTool.invoke(\"Langchain\");\n\nconsole.log(response);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Page: LangChain",
                                "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.",
                                "",
                                "",
                                "== History ==",
                                "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project's Discord server, many YouTube tutorials, and meetups in San Francisco and London. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.",
                                "In the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.",
                                "In October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.",
                                "",
                                "",
                                "== Capabilities ==",
                                "LangChain's developers highlight the framework's applicability to use-cases including chatbots, retrieval-augmented generation,  document summarization, and synthetic data generation.",
                                "As of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database to store and retrieve vector embeddings; Weaviate vector database to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK. As of April 2023, it can read from more than 50 document types and data sources.",
                                "",
                                "",
                                "== LangChain tools ==",
                                "",
                                "",
                                "== References ==",
                                "",
                                "",
                                "== External links ==",
                                "",
                                "Official website",
                                "Discord server support hub",
                                "Langchain-ai on GitHub",
                                "",
                                "Page: Milvus (vector database)",
                                "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.",
                                "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.",
                                "",
                                "",
                                "== History ==",
                                "Milvus has been developed by Zilliz since 2017.",
                                "Milvus joined Linux foundation as an incubation project in January 2020 and became a graduate in June 2021. The details about its architecture and possible applications were presented on ACM SIGMOD Conference in 2021",
                                "Milvus 2.0, a major redesign of the whole product with a new architecture, was released in January 2022.",
                                "",
                                "",
                                "== Features ==",
                                "",
                                "",
                                "=== Similarity search ===",
                                "Major similarity search related features that are available in the active 2.4.x Milvus branch:",
                                "",
                                "In-memory, on-disk and GPU indices,",
                                "Single query, batch query and range query search,",
                                "Support of sparse v",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "The tool has the following defaults associated with it:"
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { zodToJsonSchema } from \"zod-to-json-schema\";\n\nconsole.log(`Name: ${wikipediaTool.name}`);\nconsole.log(`Description: ${wikipediaTool.description}`);\nconsole.log(`Return Direct?: ${wikipediaTool.returnDirect}`);\n\nconsole.log(\"Schema:\");\nzodToJsonSchema(wikipediaTool.schema);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "Name: wikipedia-api",
                                "Description: A tool for interacting with and fetching data from the Wikipedia API.",
                                "Return Direct?: false",
                                "Schema:",
                                ""
                            ]
                        }
                    ]
                },
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "{",
                                "  type: \u001b[32m'object'\u001b[39m,",
                                "  properties: {",
                                "    input: {",
                                "      type: \u001b[32m'string'\u001b[39m",
                                "    }",
                                "  },",
                                "  additionalProperties: \u001b[33mfalse\u001b[39m,",
                                "  \u001b[32m'$schema'\u001b[39m: \u001b[32m'http://json-schema.org/draft-07/schema#'\u001b[39m",
                                "}"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "### Calculator Tool\n\nLangChain come with pre-defined tools which can be loaded using their tools names.\nThe calculator tool is used to evaluate mathematical expressions."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { Calculator } from \"@langchain/community/tools/calculator\";\n\nconst calculatorTool = new Calculator();\nconst sum = await calculatorTool.invoke(\"99 + 99\");\n\nconsole.log(\"The sum of 99 and 99 is:\", sum);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "The sum of 99 and 99 is: 198",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "### DuckDuckGoSearch Tool\nDuckDuckGoSearch offers a privacy-focused search API designed for LLM Agents. It provides seamless integration with a wide range of data sources, prioritizing user privacy and relevant search results."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { DuckDuckGoSearch } from \"@langchain/community/tools/duckduckgo_search\";\n\nconst searchTool = new DuckDuckGoSearch({ maxResults: 3 });\n\nvar response = await searchTool.invoke(\"What is the current weather in Zurich?\");\n\nconsole.log(response);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.error",
                            "value": {
                                "name": "Error",
                                "message": "DDG detected an anomaly in the request, you are likely making requests too quickly.",
                                "stack": "    at search (/Users/mikolo/Projects/Personal/LLM-Workshop/excercises/node_modules/duck-duck-scrape/lib/search/search.js:80:15)\n    at processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async DuckDuckGoSearch._call (/Users/mikolo/Projects/Personal/LLM-Workshop/excercises/node_modules/@langchain/community/dist/tools/duckduckgo_search.cjs:110:29)\n    at async DuckDuckGoSearch.call (/Users/mikolo/Projects/Personal/LLM-Workshop/excercises/node_modules/@langchain/core/dist/tools/index.cjs:111:22)\n    at async <Cell 14> [5, 0]\n    at async C (/Users/mikolo/.vscode/extensions/donjayamanne.typescript-notebook-2.0.6/out/extension/server/index.js:2:113337)\n    at async t.execCode (/Users/mikolo/.vscode/extensions/donjayamanne.typescript-notebook-2.0.6/out/extension/server/index.js:2:114306)"
                            }
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "### Custom Tool\n\nYou can define custom tools using the `tool` wrapper function.\nLet's define custom tool that returns the current date regardless of the input."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { z } from \"zod\";\nimport { tool } from \"@langchain/core/tools\";\n\nconst currDateSchema = z.object({});\nconst currDateTool = tool(\n  async (input): Promise<string> => {\n    return new Date().toLocaleDateString(\"en-GB\");\n  },\n  {\n    name: \"currDate\",\n    description: `Returns todays date, use this for any \\\n    questions related to knowing todays date. \\\n    The input should always be an empty string, \\\n    and this function will always return todays \\\n    date - any date math should occur \\\n    outside this function. Whenever there is a reference\n    to the word \"today\" or the current date\n    you have to use this tool.Adds two numbers together`,\n    schema: currDateSchema,\n  }\n);\n\nawait currDateTool.invoke({});"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "text/plain",
                            "value": [
                                "\u001b[32m'06/12/2024'\u001b[39m"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "### Retriever Tool\n\nIt is very handy to express `Retriever` (for RAG) as a tool. Let's use the example we already used in Lab4."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { CheerioWebBaseLoader } from \"@langchain/community/document_loaders/web/cheerio\";\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\nimport { FaissStore } from \"@langchain/community/vectorstores/faiss\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\n\nvar loader = new CheerioWebBaseLoader(\n    \"https://js.langchain.com/docs/concepts/\",\n    { selector: \"article\" }\n);\nvar webDocs = await loader.load();\n\nvar textSplitter = new RecursiveCharacterTextSplitter({\n    chunkSize: 1000,\n    chunkOverlap: 200,\n});\nvar documents = await textSplitter.splitDocuments(webDocs);\n\nvar vectorStore = await FaissStore.fromDocuments(documents, new OpenAIEmbeddings({\n    apiKey: process.env.OPENAI_API_KEY,\n    model: \"text-embedding-3-small\",\n}));\nvar retriever = vectorStore.asRetriever();\n\nvar result = await retriever.invoke(\"What are agents?\");\n\ndisplay.markdown(result[0].pageContent);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "text/markdown",
                            "value": [
                                "stores: Storage of and efficient search over vectors and associated metadata.Retriever: A component that returns relevant documents from a knowledge base in response to a query.Retrieval Augmented Generation (RAG): A technique that enhances language models by combining them with external knowledge bases.Agents: Use a language model to choose a sequence of actions to take. Agents can interact with external resources via tool.Prompt templates: Component for factoring out the static parts of a model \"prompt\" (usually a sequence of messages). Useful for serializing, versioning, and reusing these static parts.Output parsers: Responsible for taking the output of a model and transforming it into a more suitable format for downstream tasks. Output parsers were primarily useful prior to the general availability of tool calling and structured outputs.Few-shot prompting: A technique for improving model performance by providing a few examples of the task to perform in the prompt.Example"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "Now that we have populated our index that we will do doing retrieval over, we can easily turn it into a tool (the format needed for an agent to properly use it)."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { createRetrieverTool } from \"langchain/tools/retriever\";\n\nconst retrieverTool = createRetrieverTool(\n    retriever,\n    {\n        name: \"langchain_search\",\n        description: \"Search for information about LangChain. For any questions about LangChain, you must use this tool!\",\n    }\n);\n\nvar result = await retrieverTool.invoke({query: \"What are agents?\"});\n\ndisplay.markdown(result);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "text/markdown",
                            "value": [
                                "stores: Storage of and efficient search over vectors and associated metadata.Retriever: A component that returns relevant documents from a knowledge base in response to a query.Retrieval Augmented Generation (RAG): A technique that enhances language models by combining them with external knowledge bases.Agents: Use a language model to choose a sequence of actions to take. Agents can interact with external resources via tool.Prompt templates: Component for factoring out the static parts of a model \"prompt\" (usually a sequence of messages). Useful for serializing, versioning, and reusing these static parts.Output parsers: Responsible for taking the output of a model and transforming it into a more suitable format for downstream tasks. Output parsers were primarily useful prior to the general availability of tool calling and structured outputs.Few-shot prompting: A technique for improving model performance by providing a few examples of the task to perform in the prompt.Example",
                                "",
                                "performance and effectiveness of AI applications. This involves testing the model's responses against a set of predefined criteria or benchmarks to ensure it meets the desired quality standards and fulfills the intended purpose. This process is vital for building reliable applications.Glossary​AIMessageChunk: A partial response from an AI message. Used when streaming responses from a chat model.AIMessage: Represents a complete response from an AI model.StructuredTool: The base class for all tools in LangChain.batch: Use to execute a runnable with batch inputs a Runnable.bindTools: Allows models to interact with tools.Caching: Storing results to avoid redundant calls to a chat model.Context window: The maximum size of input a chat model can process.Conversation patterns: Common patterns in chat interactions.Document: LangChain's representation of a document.Embedding models: Models that generate vector embeddings for various data types.HumanMessage: Represents a message from a human",
                                "",
                                "chat history: Techniques to maintain and manage the chat history.OpenAI format: OpenAI's message format for chat models.Propagation of RunnableConfig: Propagating configuration through Runnables.RemoveMessage: An abstraction used to remove a message from chat history, used primarily in LangGraph.role: Represents the role (e.g., user, assistant) of a chat message.RunnableConfig: Use to pass run time information to Runnables (e.g., runName, runId, tags, metadata, maxConcurrency, recursionLimit, configurable).Standard parameters for chat models: Parameters such as API key, temperature, and maxTokens,stream: Use to stream output from a Runnable or a graph.Tokenization: The process of converting data into tokens and vice versa.Tokens: The basic unit that a language model reads, processes, and generates under the hood.Tool artifacts: Add artifacts to the output of a tool that will not be sent to the model, but will be available for downstream processing.Tool binding: Binding tools to",
                                "",
                                "general availability of tool calling and structured outputs.Few-shot prompting: A technique for improving model performance by providing a few examples of the task to perform in the prompt.Example selectors: Used to select the most relevant examples from a dataset based on a given input. Example selectors are used in few-shot prompting to select examples for a prompt.Callbacks: Callbacks enable the execution of custom auxiliary code in built-in components. Callbacks are used to stream outputs from LLMs in LangChain, trace the intermediate steps of an application, and more.Tracing: The process of recording the steps that an application takes to go from input to output. Tracing is essential for debugging and diagnosing issues in complex applications.Evaluation: The process of assessing the performance and effectiveness of AI applications. This involves testing the model's responses against a set of predefined criteria or benchmarks to ensure it meets the desired quality standards and"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "## Using Language Models\n\nNext, let's learn how to use a language model by to call tools. We will start with a bare chat model."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import {\n    HumanMessage,\n} from \"@langchain/core/messages\";\n\nvar response = await chat.invoke([new HumanMessage(\"hi!\")]);\n\ndisplay.markdown(response.content);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "text/markdown",
                            "value": [
                                "Hello! How can I assist you today?"
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "In order to enable the tools we use `.bindTools` to give the language model knowledge of these tools."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "var tools = [searchTool, retrieverTool, currDateTool, calculatorTool];\nvar chatWithTools = chat.bindTools(tools);"
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                "We can now call the model. Let's first call it with a normal message, and see how it responds. We can look at both the `content` field as well as the `tool_calls` field."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "import { HumanMessage } from \"@langchain/core/messages\";\n\nvar response = await chatWithTools.invoke([new HumanMessage(\"hi!\")]);\n\nconsole.log(`ContentString: ${response.content}`);\nconsole.log(\"ToolCalls:\");\nconsole.log(response.tool_calls);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "ContentString: Hello! How can I assist you today?",
                                "ToolCalls:",
                                "[]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "Now, let's try calling it with some input that would expect a tool to be called."
            ],
            "outputs": []
        },
        {
            "language": "javascript",
            "source": [
                "var response = await chatWithTools.invoke([new HumanMessage(\"What is the weather in Zurich today?\")]);\n\nconsole.log(`ContentString: ${response.content}`);\nconsole.log(\"ToolCalls:\");\nconsole.log(response.tool_calls);"
            ],
            "outputs": [
                {
                    "items": [
                        {
                            "mime": "application/vnd.code.notebook.stdout",
                            "value": [
                                "ContentString: ",
                                "ToolCalls:",
                                "[",
                                "  {",
                                "    name: 'duckduckgo-search',",
                                "    args: { input: 'Zurich weather today' },",
                                "    type: 'tool_call',",
                                "    id: 'call_z7iS03rmM55OE5BZGs7Snfag'",
                                "  }",
                                "]",
                                ""
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "language": "markdown",
            "source": [
                "We can see that there's now no content, but there is a tool call! It wants us to call the `duckduckgo-search` tool.\n\nThis isn't calling that tool yet - it's just telling us to. In order to actually calll it, we'll want to create our agent."
            ],
            "outputs": []
        },
        {
            "language": "markdown",
            "source": [
                ""
            ],
            "outputs": []
        }
    ]
}